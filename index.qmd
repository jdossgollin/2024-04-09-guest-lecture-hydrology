---
title: "What does probability have to do with flood risk assessment and management?"
date: 2024-04-09
author: "James Doss-Gollin"
institute: "Rice University"
venue: "CEVE 421/509"

mainfont: "Merriweather"
sansfont: "Mallory"
monofont: "JuliaMono"
format: 
    revealjs:

        theme: _assets/sass/revealjs.scss
        
        # page numbering
        slide-number: c/t
        show-slide-number: all
        hash-type: number

        # page layout and transition
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: false
        history: false
        menu:
            numbers: true
        scrollable: true
        preview-links: auto
        
        # code, links, and refs
        link-external-newwindow: true
        citations-hover: true
        code-annotations: below
        
        # math and code
        html-math-method: mathjax
        include-in-header: _assets/html/mathjax-config.html
        date-format: "ddd., MMM. D"

        footer: "James Doss-Gollin"

        title-slide-attributes:
            data-background-image: _assets/img/houston/martinez-harvey.JPG
            data-background-size: "cover"
            data-background-opacity: "0.7"

        template-partials: 
            - _assets/html/title-slide.html

# references
bibliography: _bibliography/library.bib
csl: _assets/references/american-geophysical-union.csl

# reveal-auto-agenda extension
filters:
  - reveal-auto-agenda

auto-agenda:
  bullets: numbered
  heading: Today

kernel: julia-1.10
execute: 
  cache: true
  freeze: true
---

```{julia}
#| output: false
#| echo: false
using DataFrames
using Extremes
using Gadfly
```

## Follow along!

::: {.columns}
::: {.column width="45%"}
![](_assets/img/qr.png)
:::
::: {.column width="55%"}
- Code: [github.com/jdossgollin/2024-04-09-guest-lecture-hydrology/](https://github.com/jdossgollin/2024-04-09-guest-lecture-hydrology/)
- Slides: [jdossgollin.github.io/2024-04-09-guest-lecture-hydrology/](https://jdossgollin.github.io/2024-04-09-guest-lecture-hydrology/)
- [Instructions](https://quarto.org/docs/presentations/revealjs/presenting.html#print-to-pdf) for printing to PDF
:::
:::

## How do we manage flood risk?

::: {.callout-tip}
## Your turn!
Please raise your hand and share a strategy you're familiar with.
:::

::: {.fragment}
1. Reduce emissions to mitigate future climate change
2. Real-time monitoring and forecasting
3. Building codes and design standards
4. Insurance
5. Nature-based solutions (e.g., wetlands, green infrastructure)
:::

# Flood risk assessment

---

::: {.columns}
::: {.column width="40%"}
### Hydrodynamic modeling is [part]{.text-rice-blue} of flood risk assessment {style="margin-top: 1.5em;  margin-bottom: 1.5em;"}

::: {.fragment}
But it's not the only part! Let's explore some other components.
:::
:::
::: {.column width="60%"}
![@cooper_actionable:2022](_assets/img/papers/cooper_actionable_2022_fig1.jpg)
:::
:::

---

::: {.columns}
::: {.column width="65%"}
![@sharma_stormwater:2021](_assets/img/papers/sharma-2021-fig-4a.png)
:::
::: {.column width="35%"}
### What size culvert should we install to manage stormwater? {style="margin-top: 1em;"}

::: {.fragment}
Let's break down the steps to answer this question.
:::
:::
:::

## Example workflow for culvert sizing

::: {.incremental}
1. Select an appropriate reliability level, e.g. $T=10$ years
2. From observations, estimate $T$ year _return level_ for rainfall intensity at a relevant duration, $i^*$
3. Calculate peak flow, (e.g.: $Q^* = C i^* A$ where $i^*$ is peak rainfall intensity, $A$ is area, and $C$ is runoff coefficient)
4. Size your culvert to handle $Q^* = Ci^*A$
:::

::: {.callout-tip .fragment}
## Thinking critically

1. What are the main sources of uncertainty in this workflow?
2. How might climate change affect the reliability of this approach?
:::

## How high to elevate a house to proactively reduce flood damages?

![{{< fa camera >}}:  Rob Nichols, PSU](_assets/img/nichols-ocracoke.jpeg)

::: {.fragment}
Elevating homes can reduce flood damage, but how do we determine the optimal elevation height?
:::

## Example workflow for house elevation

::: {.incremental}
1. Develop depth-damage curve
2. Estimate flood frequency at the site
3. Calculate discounted net present value of damages over time
4. Repeat for different elevation heights
5. Select the elevation height that minimizes total costs (elevation + expected damages)
:::

## Is there enough electricity supply to meet winter peaks?

:::{layout-ncol="3"}
![{{< fa camera >}}: Nakamura / Getty](_assets/img/uri_nakamura_getty.jpg)

![{{< fa camera >}}: Nakamura / Getty](_assets/img/uri_nakamura_getty_2.jpg)

![{{< fa camera >}}: Odessa / AP](_assets/img/uri_odessa_ap.jpg)
:::

::: {.fragment}
Extreme winter weather can strain electricity grids. How can we assess the risk of supply shortfalls?
:::

---

![Brian Bartholomew](_assets/img/bartholomew-ercot-feb21.jpg)

## Example workflow for electricity supply

::: {.incremental}
1. We need the **joint** distribution of demand and supply
2. Estimate winter peak demand
    1. Generate many sequences of hourly weather
    2. For each, estimate hourly demand
3. For each sequence, estimate supply...
:::

## Physical risk disclosure

![[SEC.gov](https://www.sec.gov/news/press-release/2024-31)](_assets/img/sec-disclosure.png)

::: {.fragment}
New SEC rules require companies to disclose climate-related risks. How can flood risk assessment support this?
:::

## Design a sponge city

![{{< fa camera >}} Mu Yu/Xinhua](_assets/img/sponge-cities-mu-yu.jpg)

::: {.fragment}
Sponge cities use nature-based solutions to manage flood risk. What data and models are needed to design effective sponge city strategies?
:::

## Key insights

::: {.incremental}
1. Flood modeling is one component of comprehensive flood risk assessment and management
2. Accurate flood models need to be run multiple times to explore uncertainties
3. Understanding drivers of flood hazard and risk, and how they may evolve, is crucial
4. Flood risk assessment informs a wide range of decisions, from infrastructure design to financial disclosure
:::

# Data science in flood risk assessment

## How can we estimate the probability of rare, extreme events?

::: {.columns}
::: {.column width="55%"}
1. Estimating the probability of extreme events is challenging due to limited observations
2. Simple and clever methods exist for estimating rare event likelihoods, but extrapolation is fundamentally difficult
:::
::: {.column width="45%"}
![Storm tide return levels for Galveston, TX](http://www.u-surge.net/uploads/6/4/8/8/64884233/published/screen-shot-2018-04-04-at-5-33-05-pm_1.png)
:::
:::

## Extreme value statistics

::: {.callout-tip .fragment}
## Thinking critically
Given the physical processes driving floods, does it make sense to extrapolate extreme event probabilities beyond observed records?
:::

```{julia}
#| code-fold: true
data = Extremes.dataset("portpirie")
fm = gevfit(data, :SeaLevel)

p1 = plot(data, x=:Year, y=:SeaLevel, Geom.point, Geom.line, Guide.title("Port Pirie sea level"))
p2 = returnlevelplotci(fm, 0.05)
draw(SVG(10inch, 4inch), hstack(p1, p2))
```


## Joint probability distributions

::: {.columns}
::: {.column width="50%"}
![{{< fa camera >}}: [Texas Water Newsroom](https://texaswaternewsroom.org/articles/a_coastal_flood_modeler_explains_compound_flooding.html)](_assets/img/compound_flooding.jpg)
:::
::: {.column width="50%"}
1. Accurately assessing hazard requires understanding the **joint** distribution of boundary conditions
2. Examples: antecedent moisture and rainfall; rainfall at multiple locations
:::
:::

## Copulas: A tool for modeling dependence in multivariate analysis

::: {.columns}
::: {.column width="50%"}
![Correlations across many sites drives portfolio risk [@bonnafous_waterrisk:2017]](_assets/img/papers/bonnafous_waterrisk_2017_fig4.png)
:::
::: {.column width="50%" .fragment}
![Two-variable copula [@sebastian_network:2017]](_assets/img/papers/sebastian_network_2017_fig8.jpg)
:::
:::

## Generating realistic weather sequences

1. Applications like water resources analysis and resource adequacy require long sequences of weather data
2. Historical data is limited and may not capture the full range of possible conditions
3. Single-variate extreme value analysis is insufficient, especially when storage is involved

::: {.callout-tip .fragment}
## Thinking critically
What are some limitations of relying solely on historical weather data or climate model simulations for long-term planning and risk assessment?
:::

## Downscaling

![Yuhao Liu et al., *in prep.*](_assets/img/papers/liu-downscaling.png)

## Stochastic weather generators

::: {.columns}
::: {.column width="50%"}
1. Resampling and shuffling historical data
2. Can be informed by credibly simulated climate variables
:::
::: {.column width="50%"}
![@steinschneider_semiparametric:2013](_assets/img/papers/steinschneider_semiparametric_2013_fig1.png)
:::
:::

## Trading accuracy for speed

1. Many applications, such as project screening or optimization, require running flood models hundreds or thousands of times
2. But complex flood models can be computationally expensive, making this infeasible
3. There is a fundamental trade-off between model complexity and computational cost


## Surrogate modeling

::: {.columns}
::: {.column width="60%"}
![@kazadi_neurips:2022](_assets/img/papers/kazadi_neurips_2022_fig3.png)
:::
::: {.column width="40%"}
1. Surrogate models are trained on input-output data from the complex model
2. Once trained, they provide near-instant predictions, enabling optimization and sensitivity analysis
:::
:::

## Remote sensing

::: {.columns}
::: {.column width="50%"}
1. Flooding can occur over large areas, making ground-based monitoring difficult
2. Satellite imagery enables remote mapping of flood extent and depth
3. Challenges include cloud cover and shadows
:::
::: {.column width="50%"}
![NASA's Earth-observing satellites](https://appliedsciences.nasa.gov//sites/default/files/CURRENT-Earth-Missions10_2019_0.png)
:::
:::

## Image classification

::: {.columns}
::: {.column width="60%"}
![@tellman_database:2021](_assets/img/papers/tellman_database_2021_fig3.jpeg)
:::
::: {.column width="40%"}
1. Equations derived from physical processes
2. Supervised classification algorithms (random forest, CNN)
3. And more!
:::
:::

## Key insights

::: {.incremental}
1. Flood modeling is one part of comprehensive flood risk assessment and management
2. Accurate flood models need to be run multiple times to capture uncertainty
3. Understanding drivers of flood hazard and risk, and how they may change, is crucial
4. Flood risk assessment informs diverse decisions, from infrastructure design to financial disclosure 
5. Data science plays a vital role in flood risk assessment, from boundary condition modeling to surrogate modeling and remote sensing
:::

# Getting philosophical

## Flood risk assessment faces large and often irreducible uncertainties

::: {.columns}
::: {.column width="50%"}
1. Many sources of uncertainty: future emissions, climate models, hydrologic models, exposure and vulnerability
2. Some uncertainties are inherently irreducible, such as future human behavior and decision-making
3. Uncertainty needs to be communicated and managed in flood risk assessment and decision-making
:::
::: {.column width="50%"}
![Choices of climate forcing and physical model drives large differences in sea-level rise [@doss-gollin_subjective:2022]](_assets/img/2022-elevation-robustness/lsl-evolution.jpg)
:::
:::

## Subjective choices in representing uncertainties affect outcomes

1. Subjective choices, such as selecting probability distributions or defining scenarios, can significantly impact results
2. Predictions are difficult or impossible to verify [@oreskes_verification:1994]
3. Transparency about these choices and exploring sensitivity to different assumptions is important

## Open science is critical

::: {.columns}
::: {.column width="50%"}
![](https://upload.wikimedia.org/wikipedia/commons/d/d8/UNESCO-Open_science-pillars-en.png)
:::
::: {.column width="50%"}
1. There is no single "best" approach for flood risk assessment and uncertainty quantification
2. Open science enables reproducibility, transparency, and collaboration
3. It allows for comparing and integrating different approaches, leading to more robust and credible results
:::
:::

## Tools and resources for open workflows

1. Version control systems for code: git, GitHub
2. Literate programming and reproducible analysis: Jupyter, Quarto
3. Reproducible computational environments: conda, Docker, environments
4. Open data platforms: Zenodo
5. Learning tools: Software Carpentry, Fondren, classes

# Conclusion

## Recap

::: {.incremental}
1. Flood risk assessment requires modeling exposure, vulnerability, boundary conditions, and hydrodynamics
2. Probabilistic methods like extreme value analysis and multivariate analysis are essential for estimating rare events and modeling dependence
3. Uncertainty is inherent in flood risk assessment, and subjective choices in representing uncertainty can affect outcomes
4. Open science is critical for transparency, reproducibility, and collaboration in flood risk assessment
:::

## Encouragement

::: {.incremental}
1. Skills in statistics, machine learning, and programming are increasingly important for flood risk assessment and management
2. These skills enable the application of advanced data science methods and the implementation of open and reproducible workflows
3. Seek out courses, workshops, and resources to develop these skills!
4. Domain expertise is essential for effectively applying these skills
:::

## Learn more

1. Visit [dossgollin-lab.github.io](https://dossgollin-lab.github.io)
2. Take CEVE 421 / 521
3. Take CEVE 443 / 543
4. [jdossgollin@rice.edu](mailto:jdossgollin@rice.edu)

## References

:::{#refs}
:::